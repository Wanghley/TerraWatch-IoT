#include "predictor.h"
#include "model.h"               // Generated by Python
#include "normalization_values.h" // Generated by Python

#include "tensorflow/lite/micro/all_ops_resolver.h"
#include "tensorflow/lite/micro/micro_error_reporter.h"
#include "tensorflow/lite/micro/micro_interpreter.h"
#include "tensorflow/lite/schema/schema_generated.h"
// #include "tensorflow/lite/version.h" // REMOVED: Not needed/found in this ESP32 lib version

// Define the Op Resolver. 
// Using AllOpsResolver for simplicity, but MutableOpResolver is smaller if you know specific ops.
static tflite::AllOpsResolver resolver; 

Predictor::Predictor() : 
    error_reporter(nullptr), 
    model(nullptr), 
    interpreter(nullptr), 
    tensor_arena(nullptr) {}

Predictor::~Predictor() {
    if (tensor_arena) delete[] tensor_arena;
    if (error_reporter) delete error_reporter;
    if (interpreter) delete interpreter;
}

bool Predictor::begin() {
    // 1. Setup Logging
    error_reporter = new tflite::MicroErrorReporter();

    // 2. Map the model
    model = tflite::GetModel(model_tflite);
    if (model->version() != TFLITE_SCHEMA_VERSION) {
        TF_LITE_REPORT_ERROR(error_reporter, "Model schema mismatch!");
        return false;
    }

    // 3. Allocate Memory Arena
    tensor_arena = new uint8_t[kArenaSize];

    // 4. Build Interpreter
    interpreter = new tflite::MicroInterpreter(
        model, resolver, tensor_arena, kArenaSize, error_reporter
    );

    // 5. Allocate Tensors
    TfLiteStatus allocate_status = interpreter->AllocateTensors();
    if (allocate_status != kTfLiteOk) {
        TF_LITE_REPORT_ERROR(error_reporter, "AllocateTensors() failed");
        return false;
    }

    return true;
}

float Predictor::update(SensorPacket pkt) {
    if (!interpreter) return 0.0f;

    // --- INPUT 0: THERMAL IMAGE (1, 8, 24, 1) ---
    TfLiteTensor* input_img = interpreter->input(0);
    
    // Get Quantization Params for Input 0
    float img_scale = input_img->params.scale;
    int img_zero_point = input_img->params.zero_point;

    preprocessThermal(
        pkt.thermal_left, 
        pkt.thermal_center, 
        pkt.thermal_right, 
        input_img->data.int8, 
        img_scale, 
        img_zero_point
    );

    // --- INPUT 1: SCALARS (1, 8) ---
    TfLiteTensor* input_scal = interpreter->input(1);

    // Get Quantization Params for Input 1
    float scal_scale = input_scal->params.scale;
    int scal_zero_point = input_scal->params.zero_point;

    preprocessScalars(
        pkt, 
        input_scal->data.int8, 
        scal_scale, 
        scal_zero_point
    );

    // --- INFERENCE ---
    if (interpreter->Invoke() != kTfLiteOk) {
        TF_LITE_REPORT_ERROR(error_reporter, "Invoke failed");
        return 0.0f;
    }

    // --- OUTPUT ---
    TfLiteTensor* output = interpreter->output(0);
    
    // Dequantize Output (Int8 -> Float)
    // Formula: real_val = (int_val - zero_point) * scale
    int8_t raw_out = output->data.int8[0];
    float prob = (raw_out - output->params.zero_point) * output->params.scale;

    return prob;
}

void Predictor::preprocessThermal(const float* left, const float* center, const float* right, int8_t* output_buffer, float scale, int zero_point) {
    // 1. Calculate Frame Mean for Normalization
    // We treat the 3 sensors as one large pool of pixels for the mean calculation
    float sum = 0.0f;
    for (int i = 0; i < 64; i++) sum += left[i];
    for (int i = 0; i < 64; i++) sum += center[i];
    for (int i = 0; i < 64; i++) sum += right[i];
    float frame_mean = sum / 192.0f;

    // 2. Stitch and Normalize
    // The model expects shape (8, 24).
    // The arrays are flat (64,), representing 8x8 blocks row-major.
    // We must iterate Row by Row to stitch them side-by-side.
    
    int buf_idx = 0;
    for (int row = 0; row < 8; row++) {
        int row_offset = row * 8;

        // LEFT Block
        for (int col = 0; col < 8; col++) {
            float val = left[row_offset + col];
            val = val - frame_mean; // Per-Frame Normalization
            
            // Quantize
            int8_t q_val = (int8_t)constrain(round(val / scale) + zero_point, -128, 127);
            output_buffer[buf_idx++] = q_val;
        }

        // CENTER Block
        for (int col = 0; col < 8; col++) {
            float val = center[row_offset + col];
            val = val - frame_mean; 
            int8_t q_val = (int8_t)constrain(round(val / scale) + zero_point, -128, 127);
            output_buffer[buf_idx++] = q_val;
        }

        // RIGHT Block
        for (int col = 0; col < 8; col++) {
            float val = right[row_offset + col];
            val = val - frame_mean; 
            int8_t q_val = (int8_t)constrain(round(val / scale) + zero_point, -128, 127);
            output_buffer[buf_idx++] = q_val;
        }
    }
}

void Predictor::preprocessScalars(const SensorPacket& pkt, int8_t* output_buffer, float scale, int zero_point) {
    // Extract raw values in the EXACT order defined in Python
    float raw_feats[8];
    
    // R1
    raw_feats[0] = pkt.r1.energy;
    raw_feats[1] = pkt.r1.range_cm;
    raw_feats[2] = pkt.r1.speed_ms;
    
    // R2
    raw_feats[3] = pkt.r2.energy;
    raw_feats[4] = pkt.r2.range_cm;
    raw_feats[5] = pkt.r2.speed_ms;

    // Mic
    raw_feats[6] = pkt.micL;
    raw_feats[7] = pkt.micR;

    // Normalize and Quantize
    for (int i = 0; i < 8; i++) {
        // Standard Scaling: (x - u) / s
        float val = (raw_feats[i] - SCALAR_MEAN[i]) / SCALAR_STD[i];
        
        // Quantize
        int8_t q_val = (int8_t)constrain(round(val / scale) + zero_point, -128, 127);
        output_buffer[i] = q_val;
    }
}