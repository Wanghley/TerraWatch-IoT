{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a25f252",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wanghley/Workspace/Projects/Agronauts/firmware-sensing-l1-l2/test/integration-l2/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# --- Step 1: Dependencies ---\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05a2b992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 2: Load and Parse Data ---\n",
    "# (This cell contains your `parse_data_file` function)\n",
    "# (It loads `human_data.txt` and `animal_data.txt` into `all_data`)\n",
    "\n",
    "def parse_data_file(filename):\n",
    "    \"\"\"Reads a data file, skipping headers and parsing JSON lines.\"\"\"\n",
    "    if not os.path.exists(filename):\n",
    "        print(f\"Warning: File not found - {filename}. Skipping.\")\n",
    "        return []\n",
    "    \n",
    "    data = []\n",
    "    in_data_stream = False\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip().replace('\\\\\\\\', '\\\\')\n",
    "            if line == '=== BEGIN DATA STREAM ===':\n",
    "                in_data_stream = True; continue\n",
    "            if line == '=== END DATA STREAM ===':\n",
    "                in_data_stream = False; continue\n",
    "            \n",
    "            if in_data_stream and line.startswith('{'):\n",
    "                try:\n",
    "                    data.append(json.loads(line))\n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"Warning: Could not parse line in {filename}: {line}\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b8a4e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 250 human data samples.\n",
      "Loaded 250 animal data samples.\n",
      "Total samples: 500\n"
     ]
    }
   ],
   "source": [
    "# NOTE: Update your data files to match your new format\n",
    "human_data = parse_data_file('../data/data_human.txt')\n",
    "animal_data = parse_data_file('../data/data_animal.txt')\n",
    "all_data = human_data + animal_data\n",
    "\n",
    "print(f\"Loaded {len(human_data)} human data samples.\")\n",
    "print(f\"Loaded {len(animal_data)} animal data samples.\")\n",
    "print(f\"Total samples: {len(all_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581b6a8e",
   "metadata": {},
   "source": [
    "## Step 3: Prepare Data for Mixed-Input Model\n",
    "\n",
    "This step is new. We won't create a `DataFrame`. Instead, we will create two separate input arrays for our model:\n",
    "\n",
    "1.  `X_thermal`: A 4D NumPy array `(num_samples, 8, 8, 1)` for the CNN.\n",
    "2.  `X_tabular`: A 2D NumPy array `(num_samples, 5)` for the Doppler/Mic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eecdfc38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thermal input shape: (500, 8, 8, 1)\n",
      "Tabular input shape: (500, 5)\n",
      "Labels shape: (500,)\n",
      "\n",
      "--- ESP32 SCALING CONSTANTS ---\n",
      "MEANS = [-1.695539999909699, 3.00282000374794, 11138.166, 0.0007140000037034042, 11863.846]\n",
      "STDS = [1.6808685565195818, 1.792998449711218, 42628.66762002359, 0.0004173296001566178, 7253.8063380741005]\n",
      "---------------------------------\n",
      "\n",
      "Training Thermal shape: (400, 8, 8, 1)\n",
      "Training Tabular shape: (400, 5)\n",
      "Training Labels shape: (400,)\n"
     ]
    }
   ],
   "source": [
    "# Based on your data files:\n",
    "# Doppler: 3 features (speed, range, energy)\n",
    "# Mic: 2 features (rms_mean, peak_mean)\n",
    "# Total tabular features = 5\n",
    "TABULAR_FEATURES = 5\n",
    "\n",
    "thermal_images = []\n",
    "tabular_data = []\n",
    "labels = []\n",
    "\n",
    "# --- 1. Parse all data into lists ---\n",
    "for sample in all_data:\n",
    "    try:\n",
    "        # Input 1: Thermal Image\n",
    "        thermal = np.array(sample['thermal'], dtype=np.float32)\n",
    "        if thermal.shape[0] != 64:\n",
    "            print(f\"Skipping sample, thermal is not 64 pixels: {thermal.shape[0]}\")\n",
    "            continue\n",
    "        thermal_images.append(thermal.reshape(8, 8, 1)) # Reshape for CNN\n",
    "        \n",
    "        # Input 2: Tabular Data\n",
    "        # --- FIX ---\n",
    "        # Using the keys from your original .txt files\n",
    "        tabular_data.append([\n",
    "            sample['doppler']['speed'],\n",
    "            sample['doppler']['range'],\n",
    "            sample['doppler']['energy'],\n",
    "            sample['mic']['rms_mean'],  # <-- FIXED (was 'rms')\n",
    "            sample['mic']['peak_mean'] # <-- FIXED (was 'peak')\n",
    "        ])\n",
    "        \n",
    "        # Target: Label\n",
    "        labels.append(sample['label'])\n",
    "        \n",
    "    except KeyError as e:\n",
    "        print(f\"SkiPping sample, missing key: {e}\")\n",
    "\n",
    "# --- 2. Convert lists to NumPy arrays ---\n",
    "X_thermal = np.array(thermal_images)\n",
    "X_tabular = np.array(tabular_data, dtype=np.float32)\n",
    "y_labels = np.array(labels)\n",
    "\n",
    "# --- This is the check that was failing ---\n",
    "if X_tabular.shape[0] == 0:\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"ERROR: No data was loaded into the tabular array.\")\n",
    "    print(\"This is likely a KEY MISMATCH.\")\n",
    "    print(\"Please check that the keys in the code (e.g., 'rms_mean')\")\n",
    "    print(\"exactly match the keys in your .txt data files.\")\n",
    "    print(\"=\"*50 + \"\\n\")\n",
    "else:\n",
    "    print(f\"Thermal input shape: {X_thermal.shape}\")\n",
    "    print(f\"Tabular input shape: {X_tabular.shape}\")\n",
    "    print(f\"Labels shape: {y_labels.shape}\")\n",
    "\n",
    "    # --- 3. Scale ONLY the tabular data ---\n",
    "    scaler = StandardScaler()\n",
    "    X_tabular_scaled = scaler.fit_transform(X_tabular)\n",
    "\n",
    "    # --- IMPORTANT: Save these scaling values for the ESP32! ---\n",
    "    print(\"\\n--- ESP32 SCALING CONSTANTS ---\")\n",
    "    print(f\"MEANS = {scaler.mean_.tolist()}\")\n",
    "    print(f\"STDS = {scaler.scale_.tolist()}\")\n",
    "    print(\"---------------------------------\")\n",
    "\n",
    "    # --- 4. Create Train/Test Split ---\n",
    "    X_thermal_train, X_thermal_test, \\\n",
    "    X_tabular_train, X_tabular_test, \\\n",
    "    y_train, y_test = train_test_split(\n",
    "        X_thermal,\n",
    "        X_tabular_scaled, # Use the scaled data\n",
    "        y_labels,\n",
    "        test_size=0.2,\n",
    "        stratify=y_labels,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    print(f\"\\nTraining Thermal shape: {X_thermal_train.shape}\")\n",
    "    print(f\"Training Tabular shape: {X_tabular_train.shape}\")\n",
    "    print(f\"Training Labels shape: {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7046bbd",
   "metadata": {},
   "source": [
    "## Step 4: Build the Mixed-Input Keras Model\n",
    "\n",
    "Here is the core of the new design. We use the Keras \"Functional API\" to build the two branches and merge them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17f5f293",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mixed_model(tabular_shape=5, img_shape=(8, 8, 1)):\n",
    "    # --- 1. CNN Branch (for Thermal Image) ---\n",
    "    img_input = layers.Input(shape=img_shape, name=\"thermal_input\")\n",
    "    \n",
    "    # A small, ESP32-friendly CNN\n",
    "    x = layers.Conv2D(8, kernel_size=(3, 3), activation='relu', padding='same')(img_input)\n",
    "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    cnn_output = layers.Dense(16, activation='relu')(x) # Output 16 features\n",
    "    \n",
    "    # --- 2. Vector Branch (for Doppler/Mic) ---\n",
    "    vec_input = layers.Input(shape=(tabular_shape,), name=\"vector_input\")\n",
    "    \n",
    "    # A small dense layer to process the tabular data\n",
    "    vec_output = layers.Dense(8, activation='relu')(vec_input) # Output 8 features\n",
    "\n",
    "    # --- 3. Merge Branches ---\n",
    "    combined = layers.Concatenate()([cnn_output, vec_output])\n",
    "    \n",
    "    # --- 4. Classification Head ---\n",
    "    z = layers.Dense(16, activation='relu')(combined)\n",
    "    z = layers.Dropout(0.5)(z) # Add dropout for regularization\n",
    "    output = layers.Dense(1, activation='sigmoid')(z) # Sigmoid for 0/1 probability\n",
    "    \n",
    "    # --- 5. Create and return the model ---\n",
    "    model = Model(inputs=[img_input, vec_input], outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d994ee46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ thermal_input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span> │ thermal_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ vector_input        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,064</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span> │ vector_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ thermal_input       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m)   │         \u001b[38;5;34m80\u001b[0m │ thermal_input[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m8\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ vector_input        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │      \u001b[38;5;34m2,064\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │         \u001b[38;5;34m48\u001b[0m │ vector_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │        \u001b[38;5;34m400\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m17\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,609</span> (10.19 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,609\u001b[0m (10.19 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,609</span> (10.19 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,609\u001b[0m (10.19 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = create_mixed_model(tabular_shape=TABULAR_FEATURES, img_shape=(8, 8, 1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e26e21a",
   "metadata": {},
   "source": [
    "## Step 5: Train the Mixed-Input Model\n",
    "\n",
    "When we call `model.fit()`, we have to pass the input data as a list, matching the order of our `Model` inputs: `[X_thermal_train, X_tabular_train]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38940451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the mixed-input model...\n",
      "Epoch 1/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4701 - loss: 1.1216 - val_accuracy: 0.5800 - val_loss: 0.6856\n",
      "Epoch 2/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5290 - loss: 0.7057 - val_accuracy: 0.4600 - val_loss: 0.6870\n",
      "Epoch 3/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5230 - loss: 0.7074 - val_accuracy: 0.6000 - val_loss: 0.6829\n",
      "Epoch 4/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4771 - loss: 0.7015 - val_accuracy: 0.5900 - val_loss: 0.6835\n",
      "Epoch 5/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5071 - loss: 0.7163 - val_accuracy: 0.6100 - val_loss: 0.6817\n",
      "Epoch 6/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5678 - loss: 0.6803 - val_accuracy: 0.6700 - val_loss: 0.6713\n",
      "Epoch 7/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6052 - loss: 0.6554 - val_accuracy: 0.6900 - val_loss: 0.6599\n",
      "Epoch 8/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6495 - loss: 0.6542 - val_accuracy: 0.6700 - val_loss: 0.6513\n",
      "Epoch 9/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6557 - loss: 0.6484 - val_accuracy: 0.7000 - val_loss: 0.6434\n",
      "Epoch 10/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6861 - loss: 0.6383 - val_accuracy: 0.7100 - val_loss: 0.6364\n",
      "Epoch 11/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6305 - loss: 0.6301 - val_accuracy: 0.7200 - val_loss: 0.6237\n",
      "Epoch 12/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7000 - loss: 0.5979 - val_accuracy: 0.6300 - val_loss: 0.6163\n",
      "Epoch 13/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7182 - loss: 0.5792 - val_accuracy: 0.7400 - val_loss: 0.6032\n",
      "Epoch 14/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6848 - loss: 0.5832 - val_accuracy: 0.6700 - val_loss: 0.5961\n",
      "Epoch 15/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6585 - loss: 0.5892 - val_accuracy: 0.6800 - val_loss: 0.5894\n",
      "Epoch 16/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7273 - loss: 0.5842 - val_accuracy: 0.7700 - val_loss: 0.5778\n",
      "Epoch 17/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7278 - loss: 0.5625 - val_accuracy: 0.7700 - val_loss: 0.5677\n",
      "Epoch 18/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7679 - loss: 0.5280 - val_accuracy: 0.7500 - val_loss: 0.5579\n",
      "Epoch 19/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7494 - loss: 0.5269 - val_accuracy: 0.7300 - val_loss: 0.5527\n",
      "Epoch 20/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7674 - loss: 0.5091 - val_accuracy: 0.7500 - val_loss: 0.5524\n",
      "Epoch 21/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7253 - loss: 0.5715 - val_accuracy: 0.7700 - val_loss: 0.5437\n",
      "Epoch 22/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7302 - loss: 0.5186 - val_accuracy: 0.7600 - val_loss: 0.5412\n",
      "Epoch 23/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7620 - loss: 0.5056 - val_accuracy: 0.7700 - val_loss: 0.5336\n",
      "Epoch 24/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7141 - loss: 0.5325 - val_accuracy: 0.7600 - val_loss: 0.5405\n",
      "Epoch 25/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7818 - loss: 0.5006 - val_accuracy: 0.8000 - val_loss: 0.5222\n",
      "Epoch 26/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7615 - loss: 0.4647 - val_accuracy: 0.7600 - val_loss: 0.5265\n",
      "Epoch 27/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7420 - loss: 0.5020 - val_accuracy: 0.7400 - val_loss: 0.5179\n",
      "Epoch 28/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7708 - loss: 0.4749 - val_accuracy: 0.7600 - val_loss: 0.5129\n",
      "Epoch 29/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7904 - loss: 0.4711 - val_accuracy: 0.7700 - val_loss: 0.5173\n",
      "Epoch 30/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8010 - loss: 0.4534 - val_accuracy: 0.7700 - val_loss: 0.5205\n",
      "Epoch 31/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8243 - loss: 0.4535 - val_accuracy: 0.7700 - val_loss: 0.5054\n",
      "Epoch 32/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7744 - loss: 0.4622 - val_accuracy: 0.7600 - val_loss: 0.5050\n",
      "Epoch 33/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7936 - loss: 0.4711 - val_accuracy: 0.7800 - val_loss: 0.4944\n",
      "Epoch 34/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7918 - loss: 0.4463 - val_accuracy: 0.7800 - val_loss: 0.4909\n",
      "Epoch 35/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7811 - loss: 0.4641 - val_accuracy: 0.7900 - val_loss: 0.4918\n",
      "Epoch 36/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8142 - loss: 0.4648 - val_accuracy: 0.7800 - val_loss: 0.4771\n",
      "Epoch 37/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7946 - loss: 0.4222 - val_accuracy: 0.8100 - val_loss: 0.4870\n",
      "Epoch 38/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8388 - loss: 0.4116 - val_accuracy: 0.8000 - val_loss: 0.4737\n",
      "Epoch 39/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8349 - loss: 0.4203 - val_accuracy: 0.7900 - val_loss: 0.4671\n",
      "Epoch 40/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8237 - loss: 0.4325 - val_accuracy: 0.8000 - val_loss: 0.4656\n",
      "Epoch 41/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8445 - loss: 0.3710 - val_accuracy: 0.8200 - val_loss: 0.4785\n",
      "Epoch 42/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8164 - loss: 0.4292 - val_accuracy: 0.8000 - val_loss: 0.4645\n",
      "Epoch 43/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8242 - loss: 0.3960 - val_accuracy: 0.7900 - val_loss: 0.4483\n",
      "Epoch 44/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8381 - loss: 0.4481 - val_accuracy: 0.8000 - val_loss: 0.4447\n",
      "Epoch 45/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8646 - loss: 0.3508 - val_accuracy: 0.8100 - val_loss: 0.4474\n",
      "Epoch 46/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8345 - loss: 0.3629 - val_accuracy: 0.8200 - val_loss: 0.4403\n",
      "Epoch 47/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8226 - loss: 0.4252 - val_accuracy: 0.8000 - val_loss: 0.4297\n",
      "Epoch 48/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8557 - loss: 0.3748 - val_accuracy: 0.8300 - val_loss: 0.4295\n",
      "Epoch 49/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8637 - loss: 0.3351 - val_accuracy: 0.8200 - val_loss: 0.4429\n",
      "Epoch 50/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8384 - loss: 0.4101 - val_accuracy: 0.8200 - val_loss: 0.4405\n",
      "Epoch 51/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8776 - loss: 0.3666 - val_accuracy: 0.7900 - val_loss: 0.4564\n",
      "Epoch 52/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8230 - loss: 0.4032 - val_accuracy: 0.8200 - val_loss: 0.4216\n",
      "Epoch 53/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8589 - loss: 0.3727 - val_accuracy: 0.8000 - val_loss: 0.4145\n",
      "Epoch 54/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8815 - loss: 0.3316 - val_accuracy: 0.8300 - val_loss: 0.4150\n",
      "Epoch 55/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8499 - loss: 0.3584 - val_accuracy: 0.8300 - val_loss: 0.4115\n",
      "Epoch 56/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8296 - loss: 0.3816 - val_accuracy: 0.7900 - val_loss: 0.4708\n",
      "Epoch 57/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8647 - loss: 0.3738 - val_accuracy: 0.8100 - val_loss: 0.4448\n",
      "Epoch 58/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8478 - loss: 0.3632 - val_accuracy: 0.8500 - val_loss: 0.3972\n",
      "Epoch 59/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8690 - loss: 0.3267 - val_accuracy: 0.8200 - val_loss: 0.4023\n",
      "Epoch 60/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8394 - loss: 0.3874 - val_accuracy: 0.8100 - val_loss: 0.3955\n",
      "Epoch 61/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8621 - loss: 0.3459 - val_accuracy: 0.8200 - val_loss: 0.3939\n",
      "Epoch 62/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8559 - loss: 0.3592 - val_accuracy: 0.8500 - val_loss: 0.3985\n",
      "Epoch 63/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8571 - loss: 0.3878 - val_accuracy: 0.8200 - val_loss: 0.4403\n",
      "Epoch 64/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8918 - loss: 0.3034 - val_accuracy: 0.8500 - val_loss: 0.3989\n",
      "Epoch 65/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8456 - loss: 0.3330 - val_accuracy: 0.8500 - val_loss: 0.3983\n",
      "Epoch 66/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8932 - loss: 0.2854 - val_accuracy: 0.8600 - val_loss: 0.3888\n",
      "Epoch 67/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8596 - loss: 0.3298 - val_accuracy: 0.8500 - val_loss: 0.3792\n",
      "Epoch 68/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8485 - loss: 0.3747 - val_accuracy: 0.8600 - val_loss: 0.3827\n",
      "Epoch 69/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8803 - loss: 0.3024 - val_accuracy: 0.8500 - val_loss: 0.3932\n",
      "Epoch 70/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8879 - loss: 0.2905 - val_accuracy: 0.8500 - val_loss: 0.3727\n",
      "Epoch 71/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9020 - loss: 0.2913 - val_accuracy: 0.8500 - val_loss: 0.3959\n",
      "Epoch 72/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8826 - loss: 0.3003 - val_accuracy: 0.8600 - val_loss: 0.3815\n",
      "Epoch 73/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8826 - loss: 0.2925 - val_accuracy: 0.8500 - val_loss: 0.3931\n",
      "Epoch 74/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8872 - loss: 0.3111 - val_accuracy: 0.8500 - val_loss: 0.3660\n",
      "Epoch 75/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9104 - loss: 0.2956 - val_accuracy: 0.8500 - val_loss: 0.3631\n",
      "Epoch 76/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8760 - loss: 0.3172 - val_accuracy: 0.8700 - val_loss: 0.3853\n",
      "Epoch 77/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9044 - loss: 0.2874 - val_accuracy: 0.8800 - val_loss: 0.3692\n",
      "Epoch 78/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8572 - loss: 0.3119 - val_accuracy: 0.8700 - val_loss: 0.3694\n",
      "Epoch 79/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8899 - loss: 0.3182 - val_accuracy: 0.8600 - val_loss: 0.3771\n",
      "Epoch 80/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8959 - loss: 0.2705 - val_accuracy: 0.8500 - val_loss: 0.3582\n",
      "Epoch 81/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8918 - loss: 0.2735 - val_accuracy: 0.8700 - val_loss: 0.3836\n",
      "Epoch 82/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8668 - loss: 0.3328 - val_accuracy: 0.8600 - val_loss: 0.3715\n",
      "Epoch 83/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9205 - loss: 0.2230 - val_accuracy: 0.8400 - val_loss: 0.3586\n",
      "Epoch 84/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8800 - loss: 0.2898 - val_accuracy: 0.8500 - val_loss: 0.3511\n",
      "Epoch 85/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8865 - loss: 0.2907 - val_accuracy: 0.8500 - val_loss: 0.3946\n",
      "Epoch 86/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8704 - loss: 0.3010 - val_accuracy: 0.8500 - val_loss: 0.3492\n",
      "Epoch 87/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8852 - loss: 0.3345 - val_accuracy: 0.8600 - val_loss: 0.3580\n",
      "Epoch 88/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9073 - loss: 0.2993 - val_accuracy: 0.8700 - val_loss: 0.3841\n",
      "Epoch 89/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8892 - loss: 0.2581 - val_accuracy: 0.8500 - val_loss: 0.3622\n",
      "Epoch 90/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8717 - loss: 0.3121 - val_accuracy: 0.8600 - val_loss: 0.3508\n",
      "Epoch 91/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9025 - loss: 0.2769 - val_accuracy: 0.8600 - val_loss: 0.3503\n",
      "Epoch 92/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9252 - loss: 0.2369 - val_accuracy: 0.8700 - val_loss: 0.3578\n",
      "Epoch 93/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9076 - loss: 0.2846 - val_accuracy: 0.8600 - val_loss: 0.3491\n",
      "Epoch 94/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8808 - loss: 0.3197 - val_accuracy: 0.8600 - val_loss: 0.3462\n",
      "Epoch 95/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9068 - loss: 0.2732 - val_accuracy: 0.8600 - val_loss: 0.4173\n",
      "Epoch 96/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8930 - loss: 0.2993 - val_accuracy: 0.8700 - val_loss: 0.3442\n",
      "Epoch 97/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9051 - loss: 0.2916 - val_accuracy: 0.8600 - val_loss: 0.3633\n",
      "Epoch 98/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8739 - loss: 0.2780 - val_accuracy: 0.8700 - val_loss: 0.3467\n",
      "Epoch 99/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9060 - loss: 0.2539 - val_accuracy: 0.8700 - val_loss: 0.3446\n",
      "Epoch 100/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8912 - loss: 0.2614 - val_accuracy: 0.8600 - val_loss: 0.4038\n",
      "Model training complete.\n"
     ]
    }
   ],
   "source": [
    "print(\"Training the mixed-input model...\")\n",
    "\n",
    "# Create the list of inputs for training\n",
    "X_train_list = [X_thermal_train, X_tabular_train]\n",
    "X_test_list = [X_thermal_test, X_tabular_test]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_list,\n",
    "    y_train,\n",
    "    epochs=100, # This model may need more epochs to train\n",
    "    validation_data=(X_test_list, y_test),\n",
    "    batch_size=16,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Model training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a0c696b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Loss: 0.4038\n",
      "Test Accuracy: 0.8600\n"
     ]
    }
   ],
   "source": [
    "# --- Evaluate the model on the test set ---`\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_test_list, y_test, verbose=0)\n",
    "print(f\"\\nTest Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e63a0f",
   "metadata": {},
   "source": [
    "## Step 6: Convert to TFLite and Quantize\n",
    "\n",
    "This is now more complex. The `representative_dataset` generator must provide data for *both* inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c847b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting Keras model to TensorFlow Lite...\n",
      "INFO:tensorflow:Assets written to: /var/folders/r5/m5977dy13hd_9klxgsmylm740000gn/T/tmp3xly6li4/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/r5/m5977dy13hd_9klxgsmylm740000gn/T/tmp3xly6li4/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/var/folders/r5/m5977dy13hd_9klxgsmylm740000gn/T/tmp3xly6li4'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): List[TensorSpec(shape=(None, 8, 8, 1), dtype=tf.float32, name='thermal_input'), TensorSpec(shape=(None, 5), dtype=tf.float32, name='vector_input')]\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  5415061808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5419416208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5419701168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5419700992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5419702752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5419702400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5419719488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5419718432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5419740320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5419751552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "Quantized TFLite model saved as: movement_model_cnn.tflite\n",
      "Quantized model size: 8760 bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1761849455.229785 3678178 tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "W0000 00:00:1761849455.229801 3678178 tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2025-10-30 14:37:35.229918: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/r5/m5977dy13hd_9klxgsmylm740000gn/T/tmp3xly6li4\n",
      "2025-10-30 14:37:35.230402: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2025-10-30 14:37:35.230409: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /var/folders/r5/m5977dy13hd_9klxgsmylm740000gn/T/tmp3xly6li4\n",
      "2025-10-30 14:37:35.235333: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2025-10-30 14:37:35.249362: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /var/folders/r5/m5977dy13hd_9klxgsmylm740000gn/T/tmp3xly6li4\n",
      "2025-10-30 14:37:35.254578: I tensorflow/cc/saved_model/loader.cc:471] SavedModel load for tags { serve }; Status: success: OK. Took 24659 microseconds.\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: FLOAT32, output_inference_type: FLOAT32\n",
      "2025-10-30 14:37:35.287783: W tensorflow/compiler/mlir/lite/flatbuffer_export.cc:3705] Skipping runtime version metadata in the model. This will be generated by the exporter.\n"
     ]
    }
   ],
   "source": [
    "print(\"Converting Keras model to TensorFlow Lite...\")\n",
    "\n",
    "# 1. Define the representative dataset generator\n",
    "def representative_dataset_gen():\n",
    "    # Use 100 samples from the training data\n",
    "    for i in range(100):\n",
    "        # Get one sample for each input\n",
    "        thermal_sample = X_thermal_train[i].reshape(1, 8, 8, 1)\n",
    "        tabular_sample = X_tabular_train[i].reshape(1, TABULAR_FEATURES)\n",
    "        \n",
    "        # Yield a list of inputs\n",
    "        yield [thermal_sample.astype(np.float32), tabular_sample.astype(np.float32)]\n",
    "\n",
    "# 2. Create a converter\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "# 3. Set the converter flags for INT8 quantization\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_dataset_gen\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "# Note: Input/Output types are now mixed, so let TFLite handle it.\n",
    "# We will still quantize our inputs on the ESP32 manually.\n",
    "\n",
    "# 4. Convert the model!\n",
    "tflite_quant_model = converter.convert()\n",
    "\n",
    "# 5. Save the quantized model to a file\n",
    "model_filename = 'movement_model_cnn.tflite'\n",
    "with open(model_filename, 'wb') as f:\n",
    "    f.write(tflite_quant_model)\n",
    "\n",
    "print(f\"Quantized TFLite model saved as: {model_filename}\")\n",
    "print(f\"Quantized model size: {len(tflite_quant_model)} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bd00f9",
   "metadata": {},
   "source": [
    "## Step 7: Convert TFLite Model to C Array\n",
    "\n",
    "Same as before. This creates the `.h` file you'll copy into your ESP32 project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8fe9c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 'model_data_cnn.h' file.\n",
      "\n",
      "--- First 10 lines of 'model_data_cnn.h' ---\n",
      "const unsigned char model[] = {\n",
      "unsigned char movement_model_cnn_tflite[] = {\n",
      "  0x20, 0x00, 0x00, 0x00, 0x54, 0x46, 0x4c, 0x33, 0x00, 0x00, 0x00, 0x00,\n",
      "  0x14, 0x00, 0x20, 0x00, 0x1c, 0x00, 0x18, 0x00, 0x14, 0x00, 0x10, 0x00,\n",
      "  0x0c, 0x00, 0x00, 0x00, 0x08, 0x00, 0x04, 0x00, 0x14, 0x00, 0x00, 0x00,\n",
      "  0x1c, 0x00, 0x00, 0x00, 0xb0, 0x00, 0x00, 0x00, 0x08, 0x01, 0x00, 0x00,\n",
      "  0x8c, 0x0d, 0x00, 0x00, 0x9c, 0x0d, 0x00, 0x00, 0x4c, 0x21, 0x00, 0x00,\n",
      "  0x03, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00,\n",
      "  0xa6, 0xf0, 0xff, 0xff, 0x0c, 0x00, 0x00, 0x00, 0x1c, 0x00, 0x00, 0x00,\n",
      "  0x3c, 0x00, 0x00, 0x00, 0x0f, 0x00, 0x00, 0x00, 0x73, 0x65, 0x72, 0x76,\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Use the 'xxd' tool to convert the file to a C array\n",
    "# This creates a file named 'model_data_cnn.h'\n",
    "!echo \"const unsigned char model[] = {\" > model_data_cnn.h\n",
    "!xxd -i movement_model_cnn.tflite >> model_data_cnn.h\n",
    "!echo \"};\" >> model_data_cnn.h\n",
    "\n",
    "print(\"Created 'model_data_cnn.h' file.\")\n",
    "print(\"\\n--- First 10 lines of 'model_data_cnn.h' ---\")\n",
    "!head -n 10 model_data_cnn.h\n",
    "print(\"------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1c6a9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
