{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNnr83Tvh8JusMtWWDSvah/"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "Q7cwY-1ZcaU3"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import glob\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Dense, Input, GlobalMaxPooling1D, Dropout, BatchNormalization\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.regularizers import l2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIR = \"data/\" # e.g., \"data/\"\n",
        "CLASS_0_FILES = glob.glob(f\"{DATA_DIR}/data_label_0*.jsonl\")\n",
        "CLASS_1_FILES = glob.glob(f\"{DATA_DIR}/data_label_1*.jsonl\")"
      ],
      "metadata": {
        "id": "VcJL-Ie-cc8n"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_SEQ_LEN = 198  # e.g., 25 seconds at 4Hz\n",
        "NUM_FEATURES = 202 # Adjust based on your final feature set"
      ],
      "metadata": {
        "id": "v6qwNzXMjjtf"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(line_json):\n",
        "    \"\"\"\n",
        "    Turns raw JSON into a compact feature vector.\n",
        "    WE MUST REPLICATE THIS LOGIC EXACTLY IN C++ LATER.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        data = json.loads(line_json)\n",
        "        feats = []\n",
        "\n",
        "        # --- 1. Thermal Sensors (Reduce 192 pixels to 6 values) ---\n",
        "        # We care about: Is there a hot spot? (Max) Is the whole area hot? (Mean)\n",
        "        for pos in ['left', 'center', 'right']:\n",
        "            pixels = np.array(data['thermal'][pos])\n",
        "            feats.append(np.max(pixels))  # Feature 0, 2, 4: Max Temp\n",
        "            feats.append(np.mean(pixels)) # Feature 1, 3, 5: Avg Temp\n",
        "\n",
        "        # --- 2. Radar (Log Scale) ---\n",
        "        # Energy is huge (3,000,000), so we use log() to squash it to ~15.0\n",
        "        feats.append(np.log1p(data['radar']['left']['energy']))\n",
        "        feats.append(data['radar']['left']['range'])\n",
        "\n",
        "        feats.append(np.log1p(data['radar']['right']['energy']))\n",
        "        feats.append(data['radar']['right']['range'])\n",
        "\n",
        "        # --- 3. Mic ---\n",
        "        feats.append(data['mic']['left'])\n",
        "        feats.append(data['mic']['right'])\n",
        "\n",
        "        # Total Features = 6 (Thermal) + 4 (Radar) + 2 (Mic) = 12\n",
        "        return np.array(feats, dtype=np.float32)\n",
        "\n",
        "    except (KeyError, ValueError, json.JSONDecodeError):\n",
        "        return None"
      ],
      "metadata": {
        "id": "LwjO_UKem8s6"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Load Data ---\n",
        "all_X = []\n",
        "all_y = []\n",
        "\n",
        "# Load Class 0\n",
        "for f_path in CLASS_0_FILES:\n",
        "    with open(f_path, 'r') as f:\n",
        "        seq = [extract_features(line) for line in f]\n",
        "        seq = [s for s in seq if s is not None] # Remove errors\n",
        "        if len(seq) > 0:\n",
        "            all_X.append(np.array(seq))\n",
        "            all_y.append(0)\n",
        "\n",
        "# Load Class 1\n",
        "for f_path in CLASS_1_FILES:\n",
        "    with open(f_path, 'r') as f:\n",
        "        seq = [extract_features(line) for line in f]\n",
        "        seq = [s for s in seq if s is not None]\n",
        "        if len(seq) > 0:\n",
        "            all_X.append(np.array(seq))\n",
        "            all_y.append(1)\n",
        "\n",
        "# --- Pad Sequences ---\n",
        "# Makes every recording exactly 20 steps long\n",
        "X_padded = pad_sequences(all_X, maxlen=MAX_SEQ_LEN, dtype='float32', padding='pre', truncating='post')\n",
        "y = np.array(all_y)\n",
        "\n",
        "# --- Normalize (CRITICAL FOR ESP32) ---\n",
        "# Calculate Mean and Std on the flattened data\n",
        "# We use manual calculation so we can print it easily for C++\n",
        "X_flat = np.concatenate(X_padded, axis=0)\n",
        "mean_vals = np.mean(X_flat, axis=0)\n",
        "std_vals = np.std(X_flat, axis=0) + 0.0001 # Avoid divide by zero\n",
        "\n",
        "# Apply Normalization\n",
        "X_norm = (X_padded - mean_vals) / std_vals\n",
        "\n",
        "# --- PRINT VALUES FOR C++ ---\n",
        "print(\"\\n\" + \"=\"*40)\n",
        "print(\"COPY THIS INTO YOUR ESP32 CODE\")\n",
        "print(\"=\"*40)\n",
        "print(f\"const float MEAN_VALS[] = {{ {', '.join([f'{x:.4f}' for x in mean_vals])} }};\")\n",
        "print(f\"const float STD_VALS[]  = {{ {', '.join([f'{x:.4f}' for x in std_vals])} }};\")\n",
        "print(\"=\"*40 + \"\\n\")\n",
        "\n",
        "# Split Data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_norm, y, test_size=0.2, random_state=42, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPKmvEMSnIH3",
        "outputId": "5528ca0f-5afe-422f-d798-4fed5671896c"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "========================================\n",
            "COPY THIS INTO YOUR ESP32 CODE\n",
            "========================================\n",
            "const float MEAN_VALS[] = { 26.8168, 23.8184, 27.1421, 24.3267, 34.6056, 24.6114, 1.8039, 0.1024, 8.8036, 5.0907, 0.0019, 0.0022 };\n",
            "const float STD_VALS[]  = { 3.5088, 1.2978, 3.1518, 1.6688, 5.4812, 1.5281, 4.9213, 0.6076, 7.0024, 5.2913, 0.0023, 0.0026 };\n",
            "========================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Input(shape=(MAX_SEQ_LEN, 12)), # 12 Features per step\n",
        "\n",
        "    # Simple Dense layer per timestep\n",
        "    Dense(16, activation='relu', kernel_regularizer=l2(0.01)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    # Find the strongest signal across the time sequence\n",
        "    GlobalMaxPooling1D(),\n",
        "\n",
        "    # Final Decision\n",
        "    Dropout(0.3),\n",
        "    Dense(8, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train\n",
        "model.fit(X_train, y_train, epochs=60, batch_size=8, validation_data=(X_test, y_test))\n",
        "\n",
        "# Save and Convert (Quantized)\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "# Representative dataset for quantization\n",
        "def representative_dataset():\n",
        "    for i in range(min(100, len(X_train))):\n",
        "        yield [X_train[i].reshape(1, MAX_SEQ_LEN, 12).astype(np.float32)]\n",
        "\n",
        "converter.representative_dataset = representative_dataset\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.inference_input_type = tf.int8\n",
        "converter.inference_output_type = tf.int8\n",
        "\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Write to file\n",
        "with open('model.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "print(\"Model saved as model.tflite. Run 'xxd -i model.tflite > model.h' to convert.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3FUB36tnT3V",
        "outputId": "7ed26bc9-2251-4836-e7d9-396db6f6459b"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step - accuracy: 0.5714 - loss: 3.7691 - val_accuracy: 0.5000 - val_loss: 2.2453\n",
            "Epoch 2/60\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353ms/step - accuracy: 0.5714 - loss: 1.9429 - val_accuracy: 0.5000 - val_loss: 2.1945\n",
            "Epoch 3/60\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - accuracy: 0.5714 - loss: 3.0648 - val_accuracy: 0.5000 - val_loss: 2.1431\n",
            "Epoch 4/60\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - accuracy: 0.5714 - loss: 3.0215 - val_accuracy: 0.5000 - val_loss: 2.0936\n",
            "Epoch 5/60\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290ms/step - accuracy: 0.5714 - loss: 3.6737 - val_accuracy: 0.5000 - val_loss: 2.0438\n",
            "Epoch 6/60\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - accuracy: 0.5714 - loss: 1.0288 - val_accuracy: 0.5000 - val_loss: 1.9979\n",
            "Epoch 7/60\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285ms/step - accuracy: 0.5714 - loss: 4.1176 - val_accuracy: 0.5000 - val_loss: 1.9544\n",
            "Epoch 8/60\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.5714 - loss: 3.8133 - val_accuracy: 0.5000 - val_loss: 1.9055\n",
            "Epoch 9/60\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.4286 - loss: 4.4554 - val_accuracy: 0.5000 - val_loss: 1.8588\n",
            "Epoch 10/60\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.4286 - loss: 2.6256 - val_accuracy: 0.5000 - val_loss: 1.8118\n",
            "Epoch 11/60\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.5714 - loss: 2.5020 - val_accuracy: 0.5000 - val_loss: 1.7678\n",
            "Epoch 12/60\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.5714 - loss: 2.8465 - val_accuracy: 0.5000 - val_loss: 1.7256\n",
            "Epoch 13/60\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.5714 - loss: 3.0128 - val_accuracy: 0.5000 - val_loss: 1.6845\n",
            "Epoch 14/60\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.5714 - loss: 1.8070 - val_accuracy: 0.5000 - val_loss: 1.6447\n",
            "Epoch 15/60\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.5714 - loss: 1.7908 - val_accuracy: 0.5000 - val_loss: 1.6057\n",
            "Epoch 16/60\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.4286 - loss: 2.4673 - val_accuracy: 0.5000 - val_loss: 1.5689\n",
            "Epoch 17/60\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.7143 - loss: 2.1741 - val_accuracy: 0.5000 - val_loss: 1.5356\n",
            "Epoch 18/60\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.5714 - loss: 2.1553 - val_accuracy: 0.5000 - val_loss: 1.5033\n",
            "Epoch 19/60\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.4286 - loss: 2.4503 - val_accuracy: 0.0000e+00 - val_loss: 1.4721\n",
            "Epoch 20/60\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.5714 - loss: 1.4362 - val_accuracy: 0.0000e+00 - val_loss: 1.4413\n",
            "Epoch 21/60\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.5714 - loss: 1.0396 - val_accuracy: 0.0000e+00 - val_loss: 1.4155\n",
            "Epoch 22/60\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.5714 - loss: 1.4365 - val_accuracy: 0.0000e+00 - val_loss: 1.3904\n",
            "Epoch 23/60\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.5714 - loss: 2.0576 - val_accuracy: 0.0000e+00 - val_loss: 1.3653\n",
            "Epoch 24/60\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.5714 - loss: 2.0312 - val_accuracy: 0.0000e+00 - val_loss: 1.3398\n",
            "Epoch 25/60\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.7143 - loss: 2.0433 - val_accuracy: 0.0000e+00 - val_loss: 1.3147\n",
            "Epoch 26/60\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.7143 - loss: 1.3640 - val_accuracy: 0.0000e+00 - val_loss: 1.2884\n",
            "Epoch 27/60\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.5714 - loss: 1.6857 - val_accuracy: 0.0000e+00 - val_loss: 1.2613\n",
            "Epoch 28/60\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.5714 - loss: 1.3192 - val_accuracy: 0.0000e+00 - val_loss: 1.2369\n",
            "Epoch 29/60\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.5714 - loss: 1.3762 - val_accuracy: 0.0000e+00 - val_loss: 1.2133\n",
            "Epoch 30/60\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.5714 - loss: 1.4662 - val_accuracy: 0.0000e+00 - val_loss: 1.1931\n",
            "Epoch 31/60\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.8571 - loss: 0.7187 - val_accuracy: 0.0000e+00 - val_loss: 1.1765\n",
            "Epoch 32/60\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.8571 - loss: 0.4668 - val_accuracy: 0.0000e+00 - val_loss: 1.1626\n",
            "Epoch 33/60\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.5714 - loss: 1.6144 - val_accuracy: 0.0000e+00 - val_loss: 1.1524\n",
            "Epoch 34/60\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.7143 - loss: 0.4917 - val_accuracy: 0.0000e+00 - val_loss: 1.1436\n",
            "Epoch 35/60\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.7143 - loss: 0.7850 - val_accuracy: 0.0000e+00 - val_loss: 1.1316\n",
            "Epoch 36/60\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.8571 - loss: 0.7556 - val_accuracy: 0.0000e+00 - val_loss: 1.1215\n",
            "Epoch 37/60\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.7143 - loss: 0.9142 - val_accuracy: 0.5000 - val_loss: 1.1123\n",
            "Epoch 38/60\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.4286 - loss: 1.0125 - val_accuracy: 0.5000 - val_loss: 1.1036\n",
            "Epoch 39/60\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.7143 - loss: 0.7194 - val_accuracy: 0.5000 - val_loss: 1.0962\n",
            "Epoch 40/60\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.4286 - loss: 1.3921 - val_accuracy: 0.5000 - val_loss: 1.0912\n",
            "Epoch 41/60\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - accuracy: 0.5714 - loss: 1.2603 - val_accuracy: 0.5000 - val_loss: 1.0860\n",
            "Epoch 42/60\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.7143 - loss: 0.7440 - val_accuracy: 0.5000 - val_loss: 1.0817\n",
            "Epoch 43/60\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.5714 - loss: 1.8937 - val_accuracy: 0.5000 - val_loss: 1.0786\n",
            "Epoch 44/60\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.7143 - loss: 0.9540 - val_accuracy: 0.5000 - val_loss: 1.0755\n",
            "Epoch 45/60\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - accuracy: 0.4286 - loss: 1.2580 - val_accuracy: 0.5000 - val_loss: 1.0718\n",
            "Epoch 46/60\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.5714 - loss: 1.1705 - val_accuracy: 0.5000 - val_loss: 1.0678\n",
            "Epoch 47/60\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.5714 - loss: 1.3683 - val_accuracy: 0.5000 - val_loss: 1.0604\n",
            "Epoch 48/60\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330ms/step - accuracy: 0.7143 - loss: 0.6910 - val_accuracy: 0.5000 - val_loss: 1.0547\n",
            "Epoch 49/60\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - accuracy: 0.5714 - loss: 1.1946 - val_accuracy: 0.5000 - val_loss: 1.0499\n",
            "Epoch 50/60\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.7143 - loss: 0.5495 - val_accuracy: 0.5000 - val_loss: 1.0460\n",
            "Epoch 51/60\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.7143 - loss: 0.7081 - val_accuracy: 0.5000 - val_loss: 1.0424\n",
            "Epoch 52/60\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.7143 - loss: 0.9323 - val_accuracy: 0.5000 - val_loss: 1.0388\n",
            "Epoch 53/60\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.2857 - loss: 1.1258 - val_accuracy: 0.5000 - val_loss: 1.0351\n",
            "Epoch 54/60\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 0.3487 - val_accuracy: 0.5000 - val_loss: 1.0318\n",
            "Epoch 55/60\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.8571 - loss: 0.4902 - val_accuracy: 0.5000 - val_loss: 1.0285\n",
            "Epoch 56/60\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.8571 - loss: 0.6500 - val_accuracy: 0.5000 - val_loss: 1.0254\n",
            "Epoch 57/60\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.7143 - loss: 0.7157 - val_accuracy: 0.5000 - val_loss: 1.0214\n",
            "Epoch 58/60\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.4286 - loss: 1.5434 - val_accuracy: 0.5000 - val_loss: 1.0164\n",
            "Epoch 59/60\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.5714 - loss: 1.4948 - val_accuracy: 0.5000 - val_loss: 1.0134\n",
            "Epoch 60/60\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.5714 - loss: 0.8858 - val_accuracy: 0.5000 - val_loss: 1.0101\n",
            "Saved artifact at '/tmp/tmprfmb59k1'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 198, 12), dtype=tf.float32, name='keras_tensor_40')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  140503579655056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  140503579653136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  140503579653520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  140503579653904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  140503579656016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  140503579653712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  140503579655824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  140503579643344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  140503579654288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  140503579646416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "Model saved as model.tflite. Run 'xxd -i model.tflite > model.h' to convert.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/tensorflow/lite/python/convert.py:854: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(X_test[1].reshape(1, MAX_SEQ_LEN, 12))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPk3QOwtnXE1",
        "outputId": "04e4ea24-6098-49f5-d717-093d788b0bb9"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.76173896]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6_b3xg7noSR",
        "outputId": "ee98c4b6-90e2-422a-a7dd-f768f701bb51"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3mp6WYmanx2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import glob\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Dense, Input, GlobalMaxPooling1D, Dropout, BatchNormalization, Flatten\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "DATA_DIR = \"data/\"\n",
        "CLASS_0_FILES = glob.glob(f\"{DATA_DIR}/data_label_0*.jsonl\")\n",
        "CLASS_1_FILES = glob.glob(f\"{DATA_DIR}/data_label_1*.jsonl\")\n",
        "\n",
        "# Keep your length if you want, but 198 is very long for 4Hz (50 seconds).\n",
        "# If your events are shorter, consider lowering this to 50.\n",
        "MAX_SEQ_LEN = 198\n",
        "AUGMENTATION_FACTOR = 50 # <--- NEW: Create 50 fake copies for every 1 real file\n",
        "\n",
        "def extract_features(line_json):\n",
        "    \"\"\" Turns raw JSON into a compact feature vector (12 features). \"\"\"\n",
        "    try:\n",
        "        data = json.loads(line_json)\n",
        "        feats = []\n",
        "\n",
        "        # 1. Thermal (6 values)\n",
        "        for pos in ['left', 'center', 'right']:\n",
        "            pixels = np.array(data['thermal'][pos])\n",
        "            feats.append(np.max(pixels))\n",
        "            feats.append(np.mean(pixels))\n",
        "\n",
        "        # 2. Radar (4 values)\n",
        "        feats.append(np.log1p(data['radar']['left']['energy']))\n",
        "        feats.append(data['radar']['left']['range'])\n",
        "        feats.append(np.log1p(data['radar']['right']['energy']))\n",
        "        feats.append(data['radar']['right']['range'])\n",
        "\n",
        "        # 3. Mic (2 values)\n",
        "        feats.append(data['mic']['left'])\n",
        "        feats.append(data['mic']['right'])\n",
        "\n",
        "        return np.array(feats, dtype=np.float32)\n",
        "\n",
        "    except (KeyError, ValueError, json.JSONDecodeError):\n",
        "        return None\n",
        "\n",
        "# --- 1. LOAD REAL DATA ---\n",
        "print(\"Loading data files...\")\n",
        "real_X = []\n",
        "real_y = []\n",
        "\n",
        "# Load Class 0\n",
        "for f_path in CLASS_0_FILES:\n",
        "    with open(f_path, 'r') as f:\n",
        "        seq = [extract_features(line) for line in f]\n",
        "        seq = [s for s in seq if s is not None]\n",
        "        if len(seq) > 0:\n",
        "            real_X.append(np.array(seq))\n",
        "            real_y.append(0.0)\n",
        "\n",
        "# Load Class 1\n",
        "for f_path in CLASS_1_FILES:\n",
        "    with open(f_path, 'r') as f:\n",
        "        seq = [extract_features(line) for line in f]\n",
        "        seq = [s for s in seq if s is not None]\n",
        "        if len(seq) > 0:\n",
        "            real_X.append(np.array(seq))\n",
        "            real_y.append(1.0)\n",
        "\n",
        "# Pad to fixed length\n",
        "X_padded_real = pad_sequences(real_X, maxlen=MAX_SEQ_LEN, dtype='float32', padding='pre', truncating='post')\n",
        "y_real = np.array(real_y)\n",
        "\n",
        "print(f\"Loaded {len(X_padded_real)} real samples.\")\n",
        "\n",
        "# --- 2. AUGMENTATION ENGINE (THE MISSING PIECE) ---\n",
        "print(f\"Generating synthetic data (x{AUGMENTATION_FACTOR})...\")\n",
        "aug_X = []\n",
        "aug_y = []\n",
        "\n",
        "for i in range(len(X_padded_real)):\n",
        "    original_sample = X_padded_real[i] # Shape (198, 12)\n",
        "    label = y_real[i]\n",
        "\n",
        "    # Add the original\n",
        "    aug_X.append(original_sample)\n",
        "    aug_y.append(label)\n",
        "\n",
        "    # Create clones with random noise\n",
        "    for _ in range(AUGMENTATION_FACTOR):\n",
        "        # Add random jitter (Gaussian noise)\n",
        "        noise = np.random.normal(0, 0.05, original_sample.shape)\n",
        "\n",
        "        # Scale slightly (simulate hotter/colder environment)\n",
        "        scale = np.random.uniform(0.95, 1.05)\n",
        "\n",
        "        new_sample = (original_sample * scale) + noise\n",
        "        aug_X.append(new_sample)\n",
        "        aug_y.append(label)\n",
        "\n",
        "X_final = np.array(aug_X, dtype=np.float32)\n",
        "y_final = np.array(aug_y, dtype=np.float32)\n",
        "\n",
        "print(f\"Total Training Samples after Augmentation: {len(X_final)}\")\n",
        "\n",
        "# --- 3. NORMALIZE ---\n",
        "# Calculate stats on the AUGMENTED data\n",
        "X_flat = X_final.reshape(-1, 12)\n",
        "mean_vals = np.mean(X_flat, axis=0)\n",
        "std_vals = np.std(X_flat, axis=0) + 0.0001\n",
        "\n",
        "X_norm = (X_final - mean_vals) / std_vals\n",
        "\n",
        "# Print for ESP32\n",
        "print(\"\\n\" + \"=\"*40)\n",
        "print(\"COPY THIS INTO YOUR ESP32 CODE\")\n",
        "print(\"=\"*40)\n",
        "print(f\"const float MEAN_VALS[] = {{ {', '.join([f'{x:.4f}' for x in mean_vals])} }};\")\n",
        "print(f\"const float STD_VALS[]  = {{ {', '.join([f'{x:.4f}' for x in std_vals])} }};\")\n",
        "print(\"=\"*40 + \"\\n\")\n",
        "\n",
        "# Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_norm, y_final, test_size=0.2, random_state=42, shuffle=True)\n",
        "\n",
        "# --- 4. MODEL ---\n",
        "model = Sequential([\n",
        "    Input(shape=(MAX_SEQ_LEN, 12)),\n",
        "\n",
        "    # Slightly simpler model for stability\n",
        "    Dense(16, activation='relu', kernel_regularizer=l2(0.001)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.2),\n",
        "\n",
        "    GlobalMaxPooling1D(),\n",
        "\n",
        "    Dropout(0.2),\n",
        "    Dense(8, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train\n",
        "print(\"Starting Training...\")\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=16, validation_data=(X_test, y_test))\n",
        "\n",
        "# --- 5. EXPORT ---\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "def representative_dataset():\n",
        "    for i in range(min(100, len(X_train))):\n",
        "        yield [X_train[i].reshape(1, MAX_SEQ_LEN, 12).astype(np.float32)]\n",
        "\n",
        "converter.representative_dataset = representative_dataset\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.inference_input_type = tf.int8\n",
        "converter.inference_output_type = tf.int8\n",
        "\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "with open('model.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "print(\"Done! Download model.tflite and convert with xxd.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5BzHamsobv6",
        "outputId": "16f436ac-5909-47e5-caae-306c26a79499"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data files...\n",
            "Loaded 9 real samples.\n",
            "Generating synthetic data (x50)...\n",
            "Total Training Samples after Augmentation: 459\n",
            "\n",
            "========================================\n",
            "COPY THIS INTO YOUR ESP32 CODE\n",
            "========================================\n",
            "const float MEAN_VALS[] = { 26.7362, 23.7486, 27.0604, 24.2537, 34.5040, 24.5382, 1.7974, 0.1017, 8.7762, 5.0751, 0.0020, 0.0023 };\n",
            "const float STD_VALS[]  = { 3.5612, 1.4530, 3.2117, 1.7664, 5.5560, 1.6480, 4.9065, 0.6057, 6.9886, 5.2805, 0.0500, 0.0498 };\n",
            "========================================\n",
            "\n",
            "Starting Training...\n",
            "Epoch 1/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.5530 - loss: 3.4067 - val_accuracy: 0.5435 - val_loss: 1.3607\n",
            "Epoch 2/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5702 - loss: 1.7164 - val_accuracy: 0.5326 - val_loss: 0.7876\n",
            "Epoch 3/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5367 - loss: 0.9898 - val_accuracy: 0.6304 - val_loss: 0.5273\n",
            "Epoch 4/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6715 - loss: 0.7040 - val_accuracy: 0.8370 - val_loss: 0.4185\n",
            "Epoch 5/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6969 - loss: 0.6690 - val_accuracy: 0.9239 - val_loss: 0.3598\n",
            "Epoch 6/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7212 - loss: 0.6025 - val_accuracy: 0.9348 - val_loss: 0.3315\n",
            "Epoch 7/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7659 - loss: 0.5015 - val_accuracy: 0.9348 - val_loss: 0.3035\n",
            "Epoch 8/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7371 - loss: 0.6044 - val_accuracy: 0.9348 - val_loss: 0.2824\n",
            "Epoch 9/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7896 - loss: 0.4640 - val_accuracy: 0.9348 - val_loss: 0.2640\n",
            "Epoch 10/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8103 - loss: 0.4426 - val_accuracy: 0.9348 - val_loss: 0.2464\n",
            "Saved artifact at '/tmp/tmp270gkmlr'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 198, 12), dtype=tf.float32, name='keras_tensor_56')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  140503058569104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  140503058567376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  140503058566224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  140503056229456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  140503058566032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  140503058567952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  140503056229264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  140503056226576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  140503056230416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  140503056231184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "Done! Download model.tflite and convert with xxd.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/tensorflow/lite/python/convert.py:854: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(X_test[1].reshape(1, MAX_SEQ_LEN, 12))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9yYbYVkocT8",
        "outputId": "b17a8bc1-9418-4fbf-8292-86e2514be542"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.11562948]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate accuracy\n",
        "from sklearn.metrics import accuracy_score\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = (y_pred > 0.5).astype(int)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgVkM_ujo-8R",
        "outputId": "7df6b53e-e9d6-40a6-86f7-5fb31422eef5"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "Accuracy: 0.9347826086956522\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!xxd -i model.tflite > model.h"
      ],
      "metadata": {
        "id": "vsuNL6obpFe-"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KpVMJq2EpiaR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}